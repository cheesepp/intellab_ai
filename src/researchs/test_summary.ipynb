{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tool\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseTool, tool\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msettings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m settings\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initialize_agent, AgentType\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'core'"
     ]
    }
   ],
   "source": [
    "from logging import config\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.vectorstores import Chroma\n",
    "import psycopg2\n",
    "import openai\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import Tool\n",
    "from langchain_core.tools import BaseTool, tool\n",
    "from core.llm import get_model\n",
    "from core.settings import settings\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langgraph.managed import RemainingSteps\n",
    "from agents.llama_guard import LlamaGuardOutput\n",
    "from langgraph.graph import END, MessagesState, StateGraph\n",
    "from typing import Any\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda, RunnableSerializable\n",
    "from langchain_core.messages import BaseMessage, AIMessage, convert_to_messages\n",
    "from langchain.agents import load_tools, create_react_agent, AgentExecutor\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_groq import ChatGroq\n",
    "import re\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    " \n",
    "DB_CONNECTION_STRING = \"postgresql://postgres:123456@host.docker.internal:5433/intellab-db\"\n",
    "MAX_STRING_LENGTH = 1000000\n",
    "# DB_CONNECTION_STRING = \"postgresql://postgres:123456@localhost:5433/intellab-db\"\n",
    "\n",
    "class AgentState(MessagesState, total=False):\n",
    "    \"\"\"`total=False` is PEP589 specs.\n",
    "\n",
    "    documentation: https://typing.readthedocs.io/en/latest/spec/typeddict.html#totality\n",
    "    \"\"\"\n",
    "    course_name: str\n",
    "    course_id: str\n",
    "    response: str\n",
    "    is_contained: bool\n",
    "    \n",
    "    \n",
    "def get_schema(_):\n",
    "    db = SQLDatabase.from_uri(DB_CONNECTION_STRING)  # Adjust as needed\n",
    "    schema = db.get_table_info()\n",
    "    return schema\n",
    "\n",
    "# template = \"\"\"\n",
    "# You are tasked with summarizing lessons from a course based on a given course name. Use the provided table schema, question, SQL query, and SQL response to generate a natural language response.\n",
    "# Do not need to tell the process, just return the narutal summarization response with at least 150 words and do not abbreviate\n",
    "# Prompt Template:\n",
    "\n",
    "# Schema:\n",
    "# {schema}\n",
    "\n",
    "# Task: Based on the table schema, question, SQL query, and SQL response:\n",
    "\n",
    "# Generate the SQL query below by replacing the placeholder {course_id} with the actual course name provided by the user.\n",
    "# SQL Query:\n",
    "# SELECT lesson_name, content FROM lessons WHERE course_id = '{course_id}';\n",
    "\n",
    "# Once the query is executed, use the query result ({response}) to summarize the lessons of {course_name} and generate a natural language response to the question.\n",
    "\n",
    "# Output format: just return the summary content, not SQL generation\n",
    "\n",
    "# {response}\n",
    "# Question: Summarize all lessons for the course with name {course_name}.\n",
    "# \"\"\"\n",
    "template = \"\"\"\n",
    "You are tasked with summarizing lessons from a course based on a given course name. Use the provided question, SQL query, and SQL response to generate a natural language response.\n",
    "Do not need to tell the process, just return the narutal summarization response with AT LEAST 150 words\n",
    "Prompt Template:\n",
    "\n",
    "Task: Based on the table schema, question, SQL query, and SQL response:\n",
    "\n",
    "Use the query result ({response}) to summarize the lessons of {course_name} and generate a natural language response to the question.\n",
    "\n",
    "Output format: just return the summary content, not SQL generation\n",
    "\n",
    "{response}\n",
    "Question: Summarize all lessons for the course with name {course_name}.\n",
    "\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def run_query(course_id):\n",
    "    db = SQLDatabase.from_uri(DB_CONNECTION_STRING)  # Adjust as needed\n",
    "    query = f\"SELECT lesson_name, content FROM lessons WHERE course_id = '{course_id}' LIMIT 3\"\n",
    "    return db.run(query)\n",
    "\n",
    "# llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0.0)\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# --- Utilites ---\n",
    "def extract_course_info(input_string):\n",
    "    # Regular expression to match the course name, ID, and regenerate flag\n",
    "    pattern = r\"course name: (.*?), id: (.*?), regenerate: (true|false)\"\n",
    "    \n",
    "    # Search the string for matches\n",
    "    match = re.search(pattern, input_string, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        # Extracted groups\n",
    "        course_name = match.group(1)\n",
    "        course_id = match.group(2)\n",
    "        regenerate = match.group(3).lower() == 'true'  # Convert to boolean\n",
    "        return {\n",
    "            \"course_name\": course_name,\n",
    "            \"course_id\": course_id,\n",
    "            \"regenerate\": regenerate\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Input string does not match the expected format.\")\n",
    "\n",
    "\n",
    "# ---- extract message node ----\n",
    "def extract_message(state: AgentState) -> Literal[\"check_contained_summary\", \"generate\"]:\n",
    "    print(\"-------- EXTRACT MESSAGE ---------\")\n",
    "    message_content = state[\"messages\"][-1].content\n",
    "    extract_values = extract_course_info(message_content)\n",
    "    print(extract_values)\n",
    "    return {\n",
    "        \"course_name\": extract_values[\"course_name\"],\n",
    "        \"course_id\": extract_values[\"course_id\"],\n",
    "        \"regenerate\": extract_values[\"regenerate\"]\n",
    "    }\n",
    "\n",
    "# check summary content tool:\n",
    "# contain -> finalize response, otherwise generate\n",
    "\n",
    "# ----  check contained summary CONDITIONAL node----\n",
    "def check_contained_summary(state: AgentState) -> Literal[\"retrieve_existing\", \"generate\"]:\n",
    "    print(\"-------- CHECK CONTAINED SUMMARY ---------\")\n",
    "    course_name = state['course_name']\n",
    "    regenerate = state['regenerate']\n",
    "    query = f\"\"\"\n",
    "        SELECT summary_content\n",
    "        FROM course_summary\n",
    "        WHERE course_name = '{course_name}';\n",
    "    \"\"\"\n",
    "    db = SQLDatabase.from_uri(DB_CONNECTION_STRING)  # Adjust as needed\n",
    "    result = db.run(query)\n",
    "    if result == '' or regenerate:\n",
    "        print(\"-------- REGENERATE --------\")\n",
    "        return \"generate\"\n",
    "    print(\"-------- RETRIEVE EXISTING --------\")\n",
    "    return \"retrieve_existing\"\n",
    "\n",
    "# ---- retrieve existing summary content node ----\n",
    "def retrieve_existing(state: AgentState):\n",
    "    print(\"------- EXISTED --------\")\n",
    "    course_name = state['course_name']\n",
    "    query = f\"\"\"\n",
    "        SELECT summary_content\n",
    "        FROM course_summary\n",
    "        WHERE course_name = '{course_name}';\n",
    "    \"\"\"\n",
    "    db = SQLDatabase.from_uri(DB_CONNECTION_STRING, max_string_length=MAX_STRING_LENGTH)  # Adjust as needed\n",
    "    result = db.run(query)\n",
    "    cleaned_string = re.sub(r\"^\\[\\('\", \"\", result)\n",
    "    cleaned_string = re.sub(r\"\\',\\)\\]$\", \"\", cleaned_string)\n",
    "    return {\"response\": cleaned_string}\n",
    "\n",
    "# ---- generate node ----\n",
    "def generate(state: AgentState, config: RunnableConfig):\n",
    "    print(\"-------- GENERATE ---------\")\n",
    "    llm = get_model(config[\"configurable\"].get(\"model\", settings.DEFAULT_MODEL))\n",
    "    full_chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            schema=get_schema,\n",
    "            response=lambda vars: run_query(vars[\"course_id\"]),\n",
    "        )\n",
    "        | prompt_response\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    response = full_chain.invoke({\"course_name\": state[\"course_name\"], \"course_id\": state[\"course_id\"]})\n",
    "    with open(\"hehet.txt\", \"w\") as f:\n",
    "        f.write(response)\n",
    "    return {\"response\": response}\n",
    " \n",
    "# compare new with existing content\n",
    "# more informative and valuable -> store to db, otherwise ignore new content and get the existing\n",
    "class ComparisonContent(BaseModel):\n",
    "    \"\"\"Binary score to assess the informative between generated content and existing content.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "    \n",
    "CHECKING_SYSTEM = \"\"\"\n",
    "You are the grader system assessing whether the new summary {new_summary} of {course_name} is more informative and valuable than the existing summary content {existing_content}.\n",
    "Give a binary score 'yes' or 'no', where 'yes' means that the answer is new summary content more informative and valuable than existing content.\n",
    "\"\"\"\n",
    "\n",
    "CHECKING_PROMPT = ChatPromptTemplate.from_template(CHECKING_SYSTEM)\n",
    "\n",
    "# ---- retrieve existing summary CONDITIONAL node\n",
    "def retrieve_existing_summary(state: AgentState, config: RunnableConfig) -> Literal[\"finalize_response\", \"store_summary\"]:\n",
    "    print(\"-------- Retrieve existing Summary ---------\")\n",
    "    llm = get_model(config[\"configurable\"].get(\"model\", settings.DEFAULT_MODEL))\n",
    "    query = f\"\"\"\n",
    "        SELECT summary_content\n",
    "        FROM course_summary\n",
    "        WHERE course_name = '{state['course_name']}';\n",
    "    \"\"\"\n",
    "    db = SQLDatabase.from_uri(DB_CONNECTION_STRING, max_string_length=MAX_STRING_LENGTH)  # Adjust as needed\n",
    "    result = db.run(query)\n",
    "    cleaned_string = re.sub(r\"^\\[\\('\", \"\", result)\n",
    "    cleaned_string = re.sub(r\"\\',\\)\\]$\", \"\", cleaned_string)\n",
    "    \n",
    "    model = CHECKING_PROMPT | llm.with_structured_output(ComparisonContent)\n",
    "    comparison_grade: ComparisonContent = model.invoke({\"existing_content\": cleaned_string, \"new_summary\": state[\"response\"], \"course_name\": state[\"course_name\"]})\n",
    "    if comparison_grade.binary_score == \"no\":\n",
    "        print(\"-------- NO - RESPONSE --------\")\n",
    "        return \"finalize_response\"\n",
    "    else:\n",
    "        print(\"-------- YES - STORE --------\")\n",
    "        return \"store_summary\"\n",
    "\n",
    "# store content to db\n",
    "# ---- store summary node ----\n",
    "def store_summary(state: AgentState):\n",
    "    print(\"-------- STORE SUMMARY --------\")\n",
    "    new_content = state[\"response\"]\n",
    "    course_name = state[\"course_name\"]\n",
    "    course_id = state[\"course_id\"]\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT summary_content\n",
    "        FROM course_summary\n",
    "        WHERE course_name = '{course_name}';\n",
    "    \"\"\"\n",
    "    db = SQLDatabase.from_uri(DB_CONNECTION_STRING)  # Adjust as needed\n",
    "    result = db.run(query)\n",
    "    if result == '':\n",
    "        # No summary record exists for the course, so insert new content\n",
    "        insert_query = f\"\"\"\n",
    "            INSERT INTO course_summary (course_id, course_name, summary_content)\n",
    "            VALUES ('{course_id}', '{course_name}', '{new_content}');\n",
    "        \"\"\"\n",
    "        db.run(insert_query)\n",
    "        print(f\"New summary added for course: {course_name}.\")\n",
    "    else:\n",
    "        # Summary record exists but content is NULL, so update it\n",
    "        update_query = f\"\"\"\n",
    "            UPDATE course_summary\n",
    "            SET summary_content = '{new_content}'\n",
    "            WHERE course_id = '{course_id}';\n",
    "        \"\"\"\n",
    "        db.run(update_query)\n",
    "        print(f\"Summary updated for course: {course_name}.\")\n",
    "    # else:\n",
    "    #     print(f\"Summary already exists for course: {course_name}. No action needed.\")\n",
    "    return {\"response\": new_content}\n",
    "\n",
    "# ---- finalize response node ----\n",
    "def finalize_response(state: AgentState):\n",
    "    print(\"---FINALIZING THE RESPONSE---\")\n",
    "    print(state[\"response\"])\n",
    "    return {\"messages\": [AIMessage(content=state[\"response\"])]}\n",
    "\n",
    "\n",
    "agent = StateGraph(AgentState)\n",
    "\n",
    "agent.add_node(\"extract_message\", extract_message)\n",
    "agent.add_node(\"generate\", generate)\n",
    "agent.add_node(\"retrieve_existing\", retrieve_existing)\n",
    "agent.add_node(\"store_summary\", store_summary)\n",
    "agent.add_node(\"finalize_response\", finalize_response)\n",
    "\n",
    "agent.set_entry_point(\"extract_message\")\n",
    "agent.add_edge(\"retrieve_existing\", \"finalize_response\")\n",
    "agent.add_edge(\"store_summary\", \"finalize_response\")\n",
    "agent.add_edge(\"finalize_response\", END)\n",
    "\n",
    "agent.add_conditional_edges(\n",
    "    \"extract_message\",\n",
    "    check_contained_summary\n",
    ")\n",
    "\n",
    "agent.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    retrieve_existing_summary\n",
    ")\n",
    "\n",
    "\n",
    "summarize_assistant = agent.compile()\n",
    "\n",
    "\n",
    "# inputs = {\"messages\": [(\"human\", \"The Logic Building Problems\")]}\n",
    "# for output in summarize_assistant.stream(inputs):\n",
    "#     print(output)\n",
    "#     print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF successfully generated!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/2962318072.py:16: DeprecationWarning: \"uni\" parameter is deprecated since v2.5.1, unused and will soon be removed\n",
      "  pdf.add_font(\"DejaVu\", \"\", \"../documents/DejaVuSans.ttf\", uni=True)\n",
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/2962318072.py:17: DeprecationWarning: \"uni\" parameter is deprecated since v2.5.1, unused and will soon be removed\n",
      "  pdf.add_font(\"DejaVu\", \"B\", \"../documents/DejaVuSans-Bold.ttf\", uni=True)  # Bold font\n",
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/2962318072.py:20: DeprecationWarning: The parameter \"txt\" has been renamed to \"text\" in 2.7.6\n",
      "  pdf.cell(200, 10, txt=\"Summary\", ln=True, align=\"C\")\n",
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/2962318072.py:20: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=True use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(200, 10, txt=\"Summary\", ln=True, align=\"C\")\n",
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/2962318072.py:21: DeprecationWarning: The parameter \"txt\" has been renamed to \"text\" in 2.7.6\n",
      "  pdf.cell(200, 10, txt=f\"Date: {datetime.now().strftime('%Y-%m-%d')}\", ln=True, align=\"L\")\n",
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/2962318072.py:21: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=True use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(200, 10, txt=f\"Date: {datetime.now().strftime('%Y-%m-%d')}\", ln=True, align=\"L\")\n",
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/2962318072.py:22: DeprecationWarning: The parameter \"txt\" has been renamed to \"text\" in 2.7.6\n",
      "  pdf.multi_cell(0, 10, txt=formatted_content)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from fpdf import FPDF\n",
    "import re\n",
    "import markdown\n",
    "\n",
    "output = \"\"\"Lesson: Implement a stack using singly linked list\\\\n\\\\n• **Push Operation**: The push operation involves creating a new node, updating its data, linking it to the top of the linked list, and updating the top pointer. This operation has a time complexity of O(1) because it only requires traversing the current pointer.\\\\n• **Pop Operation**: The pop operation involves removing the first node from the linked list by updating the head pointer to the next node in the list. This operation also has a time complexity of O(1) for the same reason as the push operation.\\\\n• **Time and Auxiliary Space Complexity Analysis**: Both push and pop operations have a time complexity of O(1), making them efficient for stack operations. However, the auxiliary space complexity is O(N), where N is the size of the stack, because each node in the linked list requires additional memory.\\\\n\\\\nHere is the summary of the lesson:\\\\n\\\\nLesson: Applications, Advantages and Disadvantages of Stack\\\\n\\\\n• **Function calls**: Stacks are used to keep track of return addresses of function calls, allowing programs to return to the correct location after a function has finished executing. This is achieved through push and pop operations on the stack.\\\\n• **Efficiency**: Push and pop operations on a stack can be performed in constant time (O(1)), providing efficient access to data. This makes stacks suitable for applications where fast data retrieval is crucial.\\\\n• **Last-in, First-out (LIFO) principle**: Stacks follow the LIFO principle, ensuring that the last element added to the stack is the first one removed. This behavior is useful in many scenarios, such as function calls and expression evaluation.\\\\n\\\\nNote: I did not include the other concepts mentioned in the lesson content, as they are more related to specific applications of stacks rather than fundamental principles or techniques.\\\\n\\\\nLesson: What is Stack Data Structure? A Complete Tutorial\\\\n\\\\n• **LIFO Principle**: The stack follows the Last In First Out (LIFO) principle, where elements are added and removed in reverse order of their addition.\\\\n• **Types of Stacks**: There are two types of stacks: Fixed Size Stack and Dynamic Size Stack. Fixed size stacks have a fixed capacity, while dynamic size stacks can grow or shrink dynamically.\\\\n• **Basic Operations on Stack**: The basic operations on a stack include push, pop, top, isEmpty, and isFull. These operations allow for the manipulation of elements in the stack, including adding, removing, and checking the status of the stack.\\\\n\\\\nNote: Complexity analysis is not explicitly mentioned in the provided content, but based on general knowledge, the time complexity for these operations would be O(1) for push, pop, top, isEmpty, and isFull.\\\\n\\\\nLesson: Implement Stack using Array\\\\n\\\\n• **Initialization of Stack**: The stack is initialized by creating an array, treating its end as the top of the stack, and defining a capacity for the stack.\\\\n• **Push Operation**: The push operation adds an item to the stack. If the stack is full, it results in an overflow condition. The algorithm checks if the stack is full before pushing the element, and if so, it cannot be inserted into the stack.\\\\n• **Pop Operation**: The pop operation removes an item from the stack. If the stack is empty, it results in an underflow condition. The algorithm checks if the stack is empty before popping the element, and if so, it cannot remove any element from the stack.\\\\n\\\\nNote: The complexity analysis for each operation is as follows:\\\\n- Time Complexity: push (O(1)), pop (O(1)), peek (O(1)), isEmpty (O(1)), isFull (O(1))\\\\n- Auxiliary Space: O(n), where n is the number of items in the stack.\\\\n\\\\nBased on the provided lesson summaries, here\\'s a comprehensive overview of the key concepts and recurring techniques:\\\\n\\\\n**Overview**\\\\n\\\\nThe course covers the fundamental principles and techniques of implementing a stack data structure using different approaches. The core concept of a stack is introduced, along with its applications, advantages, and disadvantages.\\\\n\\\\n**Key Concepts**\\\\n\\\\n1. **Last-In-First-Out (LIFO) Principle**: Stacks follow this principle, ensuring that the last element added to the stack is the first one removed.\\\\n2. **Basic Operations**: Push, pop, top, isEmpty, and isFull are the basic operations on a stack, allowing for manipulation of elements in the stack.\\\\n3. **Time and Auxiliary Space Complexity Analysis**: Both push and pop operations have a time complexity of O(1), making them efficient for stack operations. However, auxiliary space complexity is O(N) due to the additional memory required for each node.\\\\n\\\\n**Recurring Techniques**\\\\n\\\\n1. **Singly Linked List Implementation**: The first lesson introduces implementing a stack using a singly linked list, which provides an efficient way to perform push and pop operations.\\\\n2. **Array-Based Implementation**: The third lesson covers implementing a stack using an array, which is useful when the capacity of the stack needs to be fixed or dynamic.\\\\n\\\\n**Common Themes**\\\\n\\\\n1. **Efficiency**: Stacks are designed to provide efficient access to data through constant-time push and pop operations.\\\\n2. **Last-In-First-Out (LIFO) Principle**: The LIFO principle is a fundamental property of stacks, ensuring that elements are removed in the reverse order of their addition.\\\\n\\\\n**Applications**\\\\n\\\\n1. **Function Calls**: Stacks are used to keep track of return addresses of function calls, allowing programs to return to the correct location after a function has finished executing.\\\\n2. **Expression Evaluation**: Stacks can be used to evaluate expressions by following the LIFO principle.\\\\n\\\\nOverall, the course provides a comprehensive introduction to stacks and their applications, highlighting the importance of efficiency, LIFO principle, and basic operations in implementing stack data structures using different approaches.\"\"\"\n",
    "formatted_content = re.sub(r\"\\\\n\", \"\\n\", output)\n",
    "# Convert Markdown to HTML\n",
    "html_text = markdown.markdown(formatted_content)\n",
    "\n",
    "pdf_path =\"./summary.pdf\"\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "\n",
    "# Load a Unicode font (make sure DejaVuSans.ttf is in the same directory)\n",
    "pdf.add_font(\"DejaVu\", \"\", \"../documents/DejaVuSans.ttf\", uni=True)\n",
    "pdf.add_font(\"DejaVu\", \"B\", \"../documents/DejaVuSans-Bold.ttf\", uni=True)  # Bold font\n",
    "\n",
    "pdf.set_font(\"DejaVu\", size=10)\n",
    "pdf.cell(200, 10, txt=\"Summary\", ln=True, align=\"C\")\n",
    "pdf.cell(200, 10, txt=f\"Date: {datetime.now().strftime('%Y-%m-%d')}\", ln=True, align=\"L\")\n",
    "pdf.multi_cell(0, 10, txt=formatted_content)\n",
    "\n",
    "# pdf.write_html(html_text)\n",
    "pdf.output(\"summary.pdf\")\n",
    "print(\"✅ PDF successfully generated!\")\n",
    "# # Save to a Markdown file\n",
    "# md_file_path = \"summary.md\"\n",
    "# with open(md_file_path, \"w\", encoding=\"utf-8\") as md_file:\n",
    "#     md_file.write(formatted_content)\n",
    "\n",
    "# print(f\"✅ Markdown file saved as {md_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF generated successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/1550329187.py:141: DeprecationWarning: \"uni\" parameter is deprecated since v2.5.1, unused and will soon be removed\n",
      "  pdf.add_font(\"DejaVu\", \"\", \"../documents/DejaVuSans.ttf\", uni=True)\n",
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/1550329187.py:142: DeprecationWarning: \"uni\" parameter is deprecated since v2.5.1, unused and will soon be removed\n",
      "  pdf.add_font(\"DejaVu\", \"B\", \"../documents/DejaVuSans-Bold.ttf\", uni=True)\n",
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/1550329187.py:149: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=True use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(0, 10, \"Summary\", ln=True, align=\"C\")\n",
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/1550329187.py:25: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  pdf.cell(5, 10, \"•\", 0, 0)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from fpdf import FPDF\n",
    "\n",
    "def process_markdown(md_text, pdf):\n",
    "    lines = md_text.split(\"\\n\")\n",
    "    \n",
    "    for line in lines:\n",
    "        if not line.strip():  # Skip empty lines\n",
    "            pdf.ln(5)\n",
    "            continue\n",
    "            \n",
    "        # Process bullet points\n",
    "        if line.strip().startswith('• '):\n",
    "            bullet_content = line.strip()[2:]  # Remove the bullet marker\n",
    "            \n",
    "            # Check if new page is needed\n",
    "            if pdf.get_y() > 270:\n",
    "                pdf.add_page()\n",
    "                \n",
    "            # Set initial position for bullet\n",
    "            current_x = pdf.l_margin\n",
    "            pdf.set_x(current_x)\n",
    "            \n",
    "            # Add bullet point\n",
    "            pdf.cell(5, 10, \"•\", 0, 0)\n",
    "            current_x += 8  # Space after bullet\n",
    "            pdf.set_x(current_x)\n",
    "            \n",
    "            # Process the bullet content with formatting\n",
    "            process_formatted_text(bullet_content, pdf, current_x)\n",
    "            pdf.ln(10)\n",
    "            \n",
    "        elif line.strip().startswith('Lesson: '):\n",
    "            # Handle lesson text\n",
    "            if pdf.get_y() > 270:\n",
    "                pdf.add_page()\n",
    "                \n",
    "            # Extract lesson text\n",
    "            lesson_parts = line.strip().split(':', 1)\n",
    "            lesson_label = lesson_parts[0] + \":\"\n",
    "            lesson_content = lesson_parts[1].strip() if len(lesson_parts) > 1 else \"\"\n",
    "            \n",
    "            # Bold the entire lesson title (label + content)\n",
    "            pdf.set_font(\"DejaVu\", \"B\", 12)\n",
    "            \n",
    "            # Get the width of the lesson title\n",
    "            title_width = pdf.get_string_width(lesson_label + \" \" + lesson_content)\n",
    "            line_width = pdf.w - 2 * pdf.l_margin\n",
    "            \n",
    "            if title_width <= line_width:\n",
    "                # If the title fits on one line, write it all in bold\n",
    "                pdf.write(10, lesson_label + \" \" + lesson_content)\n",
    "                pdf.ln(10)\n",
    "            else:\n",
    "                # If title is too long, handle wrapping\n",
    "                words = (lesson_label + \" \" + lesson_content).split()\n",
    "                x_position = pdf.l_margin\n",
    "                pdf.set_x(x_position)\n",
    "                \n",
    "                for word in words:\n",
    "                    word_width = pdf.get_string_width(word + \" \")\n",
    "                    if x_position + word_width > line_width:\n",
    "                        pdf.ln()\n",
    "                        x_position = pdf.l_margin\n",
    "                        pdf.set_x(x_position)\n",
    "                    \n",
    "                    pdf.write(10, word + \" \")\n",
    "                    x_position += word_width\n",
    "                \n",
    "                pdf.ln(10)\n",
    "            \n",
    "        else:\n",
    "            # Handle regular text\n",
    "            if pdf.get_y() > 270:\n",
    "                pdf.add_page()\n",
    "                \n",
    "            process_formatted_text(line, pdf)\n",
    "            pdf.ln(10)\n",
    "\n",
    "def process_formatted_text(text, pdf, starting_x=None):\n",
    "    \"\"\"Process text with Markdown formatting like bold (**text**) and italics (*text*)\"\"\"\n",
    "    if starting_x is not None:\n",
    "        pdf.set_x(starting_x)\n",
    "    \n",
    "    # Split the text into segments based on formatting\n",
    "    segments = []\n",
    "    current_pos = 0\n",
    "    \n",
    "    # Find all bold text (**text**)\n",
    "    bold_pattern = re.compile(r'\\*\\*(.*?)\\*\\*')\n",
    "    for match in bold_pattern.finditer(text):\n",
    "        # Add text before the match\n",
    "        if match.start() > current_pos:\n",
    "            segments.append(('normal', text[current_pos:match.start()]))\n",
    "        \n",
    "        # Add the bold text\n",
    "        segments.append(('bold', match.group(1)))\n",
    "        current_pos = match.end()\n",
    "    \n",
    "    # Add any remaining text\n",
    "    if current_pos < len(text):\n",
    "        segments.append(('normal', text[current_pos:]))\n",
    "    \n",
    "    # If no formatting was found, add the whole text as normal\n",
    "    if not segments:\n",
    "        segments.append(('normal', text))\n",
    "    \n",
    "    # Process each segment with appropriate formatting\n",
    "    line_width = pdf.w - 2 * pdf.l_margin\n",
    "    x_position = pdf.get_x()\n",
    "    \n",
    "    for format_type, content in segments:\n",
    "        # Set font based on format\n",
    "        if format_type == 'bold':\n",
    "            pdf.set_font(\"DejaVu\", \"B\", 12)\n",
    "        else:\n",
    "            pdf.set_font(\"DejaVu\", \"\", 12)\n",
    "        \n",
    "        # Process words with wrapping\n",
    "        words = content.split()\n",
    "        for word in words:\n",
    "            word_width = pdf.get_string_width(word + \" \")\n",
    "            if x_position + word_width > line_width:\n",
    "                pdf.ln()\n",
    "                x_position = pdf.l_margin\n",
    "                pdf.set_x(x_position)\n",
    "            \n",
    "            pdf.write(10, word + \" \")\n",
    "            x_position += word_width\n",
    "\n",
    "# Read Markdown content\n",
    "markdown_content = formatted_content\n",
    "def save_to_pdf(markdown_content):\n",
    "    # Initialize PDF\n",
    "    pdf = FPDF()\n",
    "    pdf.set_margins(15, 15, 15)  # Left, Top, Right margins\n",
    "    pdf.add_page()\n",
    "\n",
    "    # Add fonts\n",
    "    try:\n",
    "        pdf.add_font(\"DejaVu\", \"\", \"../documents/DejaVuSans.ttf\", uni=True)  \n",
    "        pdf.add_font(\"DejaVu\", \"B\", \"../documents/DejaVuSans-Bold.ttf\", uni=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading fonts: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Add title\n",
    "    pdf.set_font(\"DejaVu\", \"B\", 14)\n",
    "    pdf.cell(0, 10, \"Summary\", ln=True, align=\"C\")\n",
    "    pdf.ln(5)\n",
    "\n",
    "    # Process Markdown\n",
    "    try:\n",
    "        process_markdown(markdown_content, pdf)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during markdown processing: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Save PDF\n",
    "    try:\n",
    "        pdf.output(\"summary.pdf\")\n",
    "        print(\"✅ PDF generated successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving PDF: {e}\")\n",
    "        exit(1)\n",
    "save_to_pdf(formatted_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF generated successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/2893790696.py:9: DeprecationWarning: \"uni\" parameter is deprecated since v2.5.1, unused and will soon be removed\n",
      "  pdf.add_font(\"DejaVu\", \"\", \"../documents/DejaVuSans.ttf\", uni=True)\n",
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/2893790696.py:10: DeprecationWarning: \"uni\" parameter is deprecated since v2.5.1, unused and will soon be removed\n",
      "  pdf.add_font(\"DejaVu\", \"B\", \"../documents/DejaVuSans-Bold.ttf\", uni=True)\n",
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/2893790696.py:17: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=True use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  pdf.cell(0, 10, \"Summary\", ln=True, align=\"C\")\n",
      "/var/folders/bh/j4v4dmz975g6yv_z9sfv3t700000gp/T/ipykernel_79614/1169869398.py:25: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  pdf.cell(5, 10, \"•\", 0, 0)\n"
     ]
    }
   ],
   "source": [
    "def save_to_pdf(content):\n",
    "    # Initialize PDF\n",
    "    pdf = FPDF()\n",
    "    pdf.set_margins(15, 15, 15)  # Left, Top, Right margins\n",
    "    pdf.add_page()\n",
    "\n",
    "    # Add fonts\n",
    "    try:\n",
    "        pdf.add_font(\"DejaVu\", \"\", \"../documents/DejaVuSans.ttf\", uni=True)  \n",
    "        pdf.add_font(\"DejaVu\", \"B\", \"../documents/DejaVuSans-Bold.ttf\", uni=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading fonts: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Add title\n",
    "    pdf.set_font(\"DejaVu\", \"B\", 14)\n",
    "    pdf.cell(0, 10, \"Summary\", ln=True, align=\"C\")\n",
    "    pdf.ln(5)\n",
    "\n",
    "    # Process Markdown\n",
    "    try:\n",
    "        process_markdown(markdown_content, pdf)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during markdown processing: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Save PDF\n",
    "    try:\n",
    "        pdf.output(\"summary.pdf\")\n",
    "        print(\"✅ PDF generated successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving PDF: {e}\")\n",
    "        exit(1)\n",
    "save_to_pdf(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
